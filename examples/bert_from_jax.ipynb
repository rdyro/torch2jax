{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d16bfa8",
   "metadata": {},
   "source": [
    "# Calling BERT model from JAX (with BERT weights in JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd89d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.func import functional_call\n",
    "import jax\n",
    "from jax import numpy as jnp, Array\n",
    "\n",
    "from torch2jax import tree_t2j, torch2jax_with_vjp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c81e5",
   "metadata": {},
   "source": [
    "### Loading the dataset and the model (in PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa712ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/rdyro/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-v1\", split=\"train\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def tokenizer_torch(text: list[str]) -> dict[str, Tensor]:\n",
    "    encoded = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return {k: v.to(device) for (k, v) in encoded.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d93ee",
   "metadata": {},
   "source": [
    "### Let's convert the torch model to a function, using `torch.func.functional_call`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5978ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, buffers = dict(model.named_parameters()), dict(model.named_buffers())\n",
    "\n",
    "def torch_fwd_fn(params, buffers, input):\n",
    "    return functional_call(model, (params, buffers), args=(), kwargs=input).pooler_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02c0c6",
   "metadata": {},
   "source": [
    "### We do not need to specify output, the library will call the torch function ones to infer the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614c16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 50\n",
    "text = [x[\"text\"] for x in random.choices(dataset, k=int(1e3)) if len(x[\"text\"]) > 100][:nb]\n",
    "encoded_text = tokenizer_torch(text)\n",
    "\n",
    "jax_fwd_fn = jax.jit(torch2jax_with_vjp(torch_fwd_fn, params, buffers, encoded_text))\n",
    "params_jax, buffers_jax = tree_t2j(params), tree_t2j(buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247cd94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version took:   2.9324e-01 s\n",
      "Torch version took: 1.7142e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   3.5733e-01 s\n",
      "Torch version took: 2.3677e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   3.1890e-01 s\n",
      "Torch version took: 1.9941e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   4.4257e-01 s\n",
      "Torch version took: 3.2214e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   2.9708e-01 s\n",
      "Torch version took: 1.7585e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   3.2778e-01 s\n",
      "Torch version took: 2.0791e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   2.7836e-01 s\n",
      "Torch version took: 1.5862e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   3.1563e-01 s\n",
      "Torch version took: 1.9557e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   3.0478e-01 s\n",
      "Torch version took: 1.8507e-01 s\n",
      "err = 0.0000e+00\n",
      "JAX version took:   2.7461e-01 s\n",
      "Torch version took: 1.5416e-01 s\n",
      "err = 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    text = [x[\"text\"] for x in random.choices(dataset, k=int(1e3)) if len(x[\"text\"]) > 100][:nb]\n",
    "    encoded_text = tokenizer_torch(text)\n",
    "    encoded_text_jax = tree_t2j(encoded_text)\n",
    "\n",
    "    t = time.time()\n",
    "    out1 = jax_fwd_fn(params_jax, buffers_jax, encoded_text_jax)\n",
    "    t = time.time() - t\n",
    "    print(f\"JAX version took:   {t:.4e} s\")\n",
    "\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        out2 = model(**encoded_text).pooler_output\n",
    "    torch.cuda.synchronize()\n",
    "    t = time.time() - t\n",
    "    print(f\"Torch version took: {t:.4e} s\")\n",
    "    print(f\"err = {jnp.linalg.norm(out1 - tree_t2j(out2)):.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8b595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "devel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
